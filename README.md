# ğŸ§  LatentResNet â€” ImageNet Classifier using LiteAE (Autoencoder) + DeepResNet Blocks

This repository accompanies the paper **"LatentResNet: An Optimized Underwater Fish Classification Model with Low Computational Cost"**

The project is structured for both **researchers** and **practitioners**, offering a clean, modular, and reproducible codebase to experiment with deep learning classification using an autoencoder backbone (LiteAE) and custom DeepResNet blocks.

> ğŸ—ï¸ This implementation reflects the **base (large)** version of EncodDeepResNet. To explore other variants, simply adjust the configuration and hyperparameters in `src/config.py`.

---

## ğŸ“¦ Key Features

- âœ… **LiteAE** â€” Lightweight Autoencoder for Features Compression and Reconstruction  
- âœ… **DeepResNet Blocks** â€” Efficient residual units with attention  
- âœ… **LatentResNet** â€” The classification model  
- âœ… Flexible config system for architecture variants  
- âœ… Custom data augmentation pipeline  
- âœ… Multi-GPU distributed training (via `MirroredStrategy`)

---

## ğŸš€ Getting Started
### 1. Clone the Repository

```bash
git clone https://github.com/MuhabHariri/EncodDeepResNet.git
```
```bash
cd EncodDeepResNet
```


---

### 2. Install Requirements

```bash
pip install -r requirements.txt
```



---

### 3. Prepare Your Dataset
```bash
Dataset/
â”œâ”€â”€ Train/
â”‚   â”œâ”€â”€ class_1/
â”‚   â”œâ”€â”€ class_2/
â”‚   â””â”€â”€ ...
â””â”€â”€ Val/
    â”œâ”€â”€ class_1/
    â”œâ”€â”€ class_2/
    â””â”€â”€ ...
```
Update paths in src/config.py: 
```bash
TRAIN_DIR = r"E:\Dataset\Train"
VAL_DIR   = r"E:\Dataset\Val"
```

---


### 4. Train the Model 
```bash
python train.py
```
---
